nodle_data <- read_csv('./data/nodle_data.csv')
nodle_data <- read_csv('./data/nodle_data.csv', row.names(1))
nodle_data <- read_csv('./data/nodle_data.csv')
nodle_data
nodle_data <- read_csv('./data/nodle_data.csv')
nodle_data
column_to_rownames(nodle_data, var=var = 'X1')
column_to_rownames(nodle_data, var= 'X1')
nodle_data <- read_csv('./data/nodle_data.csv')
nodle_data
add_rownames(nodle_data, 'X1')
nodle_data
rownames_to_column(nodle_data)
column_to_rownames(nodle_data)
column_to_rownames(nodle_data, "X1")
column_to_rownames(nodle_data, var= "X1")
data.frame(column_to_rownames(nodle_data, var= "X1"))
nodel_data <- data.frame(column_to_rownames(nodle_data, var= "X1"))
p1 = prcomp(nodle_data, scale=T)
nodle_data <- data.frame(column_to_rownames(nodle_data, var= "X1"))
nodle_data
p1 = prcomp(nodle_data, scale=T)
p1
predict(p1)
plot(predict(p1))
biplot(p1)
nodle_data
p1 = prcomp(nodle_data, scale=T)
p1
summary(p1)
Price <- c(6,7,6,5,7,6,5,6,3,1,2,5,2,3,1,2)
Software <- c(5,3,4,7,7,4,7,5,5,3,6,7,4,5,6,3)
Aesthetics <- c(3,2,4,1,5,2,2,4,6,7,6,7,5,6,5,7)
Brand <- c(4,2,5,3,5,3,1,4,7,5,7,6,6,5,5,7)
data <- data.frame(Price, Software, Aesthetics, Brand)
data
write.csv(data, './data/computer_data_p419.csv')
read.csv('./data/computer_data_p419.csv')
read.csv('./data/computer_data_p419.csv', row.names = F)
write.csv(data, './data/computer_data_p419.csv', row.names = F)
read.csv('./data/computer_data_p419.csv')
data <- read.csv('./data/computer_data_p419.csv')
head(data)
princomp(dtaa, cor=T)
princomp(data, cor=T)
pca <- princomp(data, cor=T)
summary(pca)
predict(pca)
summary(pca)
biplot(pca)
head(data)
# ARIMA
Nile
Ideaths
ldeaths
plot(Nile)
plot(ldeaths)
str(Nile)
str(ldeaths)
# ARIMA
Nile
ldeaths
ldeaths.decompose <- decompose(ldeaths)
ldeaths.decompose
ldeaths.decompose$seasonal
plot(ldeaths.decompose)
ldeaths.decompose.adj <- ldeaths.decompose$seasonal
ldeaths.decompose.adj <- ldeaths - ldeaths.decompose$seasonal
plot(ldeaths.decompose.adj)
Nile.diff1 <- diff(Nile, differences=1)
plot(Nile.diff1)
Nile.diff2 <- diff(Nile, differences=2)
plot(Nile.diff2)
acf(Nile.diff2)
acf(Nile.diff2, lag.max=20)
acf(Nile.diff2, lag.max=20, plot=F)
pacf(Nile.diff2, lag.max=20)
pacf(Nile.diff2, lag.max=20, plot=False)
pacf(Nile.diff2, lag.max=20, plot=F)
auto.arima(Nile)
library(forecast)
install.packages('forecast')
library(forecast)
auto.arima(Nile)
arima(Nile, order=c(1,1,1))
Nile.arima <-  arima(Nile, order=c(1,1,1))
Nile.arima
Nile.forcasts <- forecast(Nile.arima, h=10)
plot(Nile.forecast)
Nile.forecasts <- forecast(Nile.arima, h=10)
plot(Nile.forecasts)
# exercise firm.csv data
firm <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)
salary <- c(3030, 6050, 3571, 3300, 0, 9375, 9525, 5000, 999, 3300, 3500, 2493,
1911, 2130, 1185, 5236, 1990, 6000, 6229, 1523)
tenure <- c(7, 0, 11, 6, 18, 6, 15, 5, 3, 2, 16, 5, 7, 4, 0, 2, 4, 32, 5, 3)
age <- c(61, 51, 63, 60, 63, 57, 60, 63, 61, 58, 59, 56, 60, 60, 74, 63, 56)
sales <- c(161315, 144416, 139208, 100697, 100469, 81667, 76431, 57813, 56154, 53588,
50777, 47678, 47061, 41322, 37154, 35853, 33674, 33296, 32379, 31707)
length(firm, salary)
length(firm)
length(salary)
length(tenure)
length(age)
age <- c(61, 51, 63, 60, 63, 57, 60, 61, 57, 60, 63, 61, 58, 59, 56, 60, 60, 74, 63, 56)
length(age)
length(sales)
profits <- c(2956, 22071, 4430, 6370, 9296, 6328, 5807, 5372, 1120, 6398, 5165, 1704, 2945, 1048, 3780, 1259,
568, 3765, 3782, 578)
length(profits)
assets <- c(257389, 237545, 49271, 92630, 355935, 86100, 668641, 59920, 36672, 59550, 617679,
42754, 33673, 30966, 299804, 14166, 19166, 194398, 3665875)
length(assets)
assets <- c(257389, 237545, 49271, 92630, 355935, 86100, 668641, 59920, 36672, 59550, 617679,
42754, 33673, 37675, 30966, 299804, 14166, 19166, 194398, 3665875)
length(assets)
data.frame(firm, salary, tenure, age, sales, profits, assets)
source('C:/Users/dsc/adp_guidebook/ADP_guide_book.R', encoding = 'UTF-8', echo=TRUE)
firm <- data.frame(firm, salary, tenure, age, sales, profits, assets)
write.csv(firm, './data/firm.csv', row.names = F)
read.csv('./data/firm.csv')
summary(firm)
summary(firm)
var(firm$salary)
sd(firm$salary)
median(firm$salary)
for (i in 2:7) {
mean_value = mean(firm[, i])
sd_value = sd(firm[, i])
median_value = median(firm[, i])
print(mean_value, sd_value, median_value)
}
show_value <- function(x) {
for (i in 2:7) {
mean_value = mean(firm[, i])
sd_value = sd(firm[, i])
median_value = median(firm[, i])
print(mean_value, sd_value, median_value)
}
}
for (i in 2:7) {
mean_value = mean(firm[, i])
sd_value = sd(firm[, i])
median_value = median(firm[, i])
print(mean_value, sd_value, median_value)
}
for (i in 2:7) {
mean_value = mean(firm[, i])
sd_value = sd(firm[, i])
median_value = median(firm[, i])
print(mean_value)
print(sd_value)
print(median_value)
}
for (i in 2:7) {
mean_value = mean(firm[, i])
sd_value = sd(firm[, i])
median_value = median(firm[, i])
print("mean : ", mean_value)
print(sd_value)
print(median_value)
}
for (i in 2:7) {
mean_value = mean(firm[, i])
sd_value = sd(firm[, i])
median_value = median(firm[, i])
print("mean : " + mean_value)
print(sd_value)
print(median_value)
}
for (i in 2:7) {
mean_value = mean(firm[, i])
sd_value = sd(firm[, i])
median_value = median(firm[, i])
print(mean_value)
print(sd_value)
print(median_value)
}
library(ggplot2)
ggplot(firm, aes(x = profit, y = salary)) + geom_point(color='blue')
ggplot(data = firm, aes(x = profit, y = firmsalary)) + geom_point(color='blue')
ggplot(data = firm, aes(x = profits, y = firmsalary)) + geom_point(color='blue')
ggplot(data = firm, aes(x = profits, y = salary)) + geom_point(color='blue')
ggplot(firm, aes(profits, salary)) + geom_point(color='blue')
ggplot(firm, aes(profits, salary)) + geom_point(color='blue', size=5)
ggplot(firm, aes(profits, salary)) + geom_point(color='blue', size=3)
lm(salary ~ profits)
lm(salary ~ profits, data = firm)
firm_lm <- lm(salary ~ profits, data = firm)
summary(firm_lm)
firm_lm_1 <- lm(salary ~ profits, data = firm)
firm_lm_1 <- lm(salary ~ profits, data = firm)
summary(firm_lm_1)
firm_lm_2 <- lm(salary ~ profits + age + sales, data=firm)
summary(firm_lm_2)
firm_lm_all <- lm(salary  ~ ., data= firm)
summary(firm_lm_all)
step(lm(salary ~ ., data=firm), direction='backward')
step(lm(salary ~ 1., data=firm), scope = list(lower=~1, upper=~tenure+sales+profits+assets),direction='forward')
step(lm(salary ~ 1., data=firm), scope = list(lower=~1, upper=~tenure+sales+profits+assets),direction='both')
data(iris)
subset(iris, Species == 'setosa' | Species = 'versicolor')
subset(iris, Species == 'setosa' | Species = 'versicolor')
subset(iris, Species == 'setosa' | Species == 'versicolor')
a <- subset(iris, Species == 'setosa' | Species == 'versicolor')
a$Species
a$Species <- as.factor(a$Species)
str(a)
glm(Species ~ Sepal.Length, family = binomial, data=a)
b <- glm(Species ~ Sepal.Length, family = binomial, data=a)
summary(b)
qchisq(138.629, df=  99)
qchisq(0.005, df=  99)
pchisq(139.629, df=99)
dchisq(139.629, df=99)
pchisq(139.629, df=99)
qchisq(139.629, df=99)
pchisq(139.629, df=99)
pchisq(139.629, df=99, lower.tail = F)
pchisq(138.629, df=99, lower.tail = F)
pchisq(64.211, df=98, lower.tail = F)
coef(b)
exp(coef(b)['Sepal.Length'])
confint(b, param='Sepal.Length')
exp(confint(b, param='Sepal.Length'))
fitted(b)[c(1:5), c(96:100)]
fitted(b)[c(1:5, 96:100)]
predict(b, newdata=a[c(1, 50, 51, 100)])
source('C:/Users/dsc/adp_guidebook/ADP_guide_book.R', encoding = 'UTF-8', echo=TRUE)
fitted(b)[c(1:5, 96:100)]
a
predict(b, newdata=a[c(1, 50, 51, 100), ], type='response')
cdplot(Species~Sepal.Length, data=1)
cdplot(Species~Sepal.Length, data=a)
plot(a$Sepal.Length, a$Species, xlab = 'Sepal.Length')
a$Species
x = seq(min(a$Sepal.Length), max(a$Sepal.Length), .1)
coef(b)
lines(x, 1+(1/(1+exp(-27.831 + 5.140*x))), type='l', col='red')
plot(a$Sepal.Length, a$Species, xlab = 'Sepal.Length')
x = seq(min(a$Sepal.Length), max(a$Sepal.Length), .1)
lines(x, 1+(1/(1+exp(-27.831 + 5.140*x))), type='l', col='red')
attach(mtcars)
str(mtcars)
glm(vs ~ mpg + am, data=mtcars, family=binomial)
glm_vs <- glm(vs ~ mpg + am, data=mtcars, family=binomial)
summary(glm_vs)
pchisq(43.860, df=31, lower.tail = F)
pchisq(20.646, df=29, lower.tail = F)
coef(glm_vs)
step_vs <- step(glm_vs, direction='backward')
step_vs
summary(step_vs)
ls(glm_vs)
str(glm_vs)
anova(glm_vs, test='Chisq')
data(iris)
a <- subset(iris, Species == 'setosa' | Species == 'versicolor')
a$Species <- as.factor(a$Species)
str(a)
b <- glm(Species ~ Sepal.Length, family = binomial, data=a)
summary(b)
pchisq(138.629, df=99, lower.tail = F)
pchisq(64.211, df=98, lower.tail = F)
coef(b)
exp(coef(b)['Sepal.Length'])
confint(b, param='Sepal.Length')
exp(confint(b, param='Sepal.Length'))
fitted(b)[c(1:5, 96:100)]
a
predict(b, newdata=a[c(1, 50, 51, 100), ], type='response')
cdplot(Species~Sepal.Length, data=a)
plot(a$Sepal.Length, a$Species, xlab = 'Sepal.Length')
x = seq(min(a$Sepal.Length), max(a$Sepal.Length), .1)
lines(x, 1+(1/(1+exp(-27.831 + 5.140*x))), type='l', col='red')
attach(mtcars)
str(mtcars)
glm_vs <- glm(vs ~ mpg + am, data=mtcars, family=binomial)
summary(glm_vs)
coef(glm_vs)
pchisq(43.860, df=31, lower.tail = F)
pchisq(20.646, df=29, lower.tail = F)
step_vs <- step(glm_vs, direction='backward')
step_vs
summary(step_vs)
ls(glm_vs)
str(glm_vs)
ls(glm_vs)
library(nnet)
nnet(Species ~., data=iris, size=2, rang=.1, decay=5e-4, maxit=200)
nn_iris <- nnet(Species ~., data=iris, size=2, rang=.1, decay=5e-4, maxit=200)
summary(nn_iris)
plot.nnet(nn.iris)
plot(nn.iris)
plot(nniris)
plot(nn_iris)
summary(nn_iris)
install.packages('clusterGeneration')
install.packages('scales')
install.packages("scales")
libary(clusterGeneration)
library(clusterGeneration)
library(scales)
install.packages('scales')
library(scales)
plot(nn_iris)
table(iris$Species, predict(nn_iris, iris, type='class'))
library(neuralnet)
install.packages('neuralnet')
library(neuralnet)
data("infert")
head(infert)
str(infert)
summary(infert)
boxplot(infert)
infert), -c('education', 'stratum')
infert[, c('education', 'stratum')]
infert[, -c('education', 'stratum')]
infert
infert %>% select(-c('educaton'))
library(tidyverse)
infert %>% select(-c('educaton'))
install.packages('scales')
# install.packages('scales')
library(scales)
library(tidyverse)
infert %>% select(-c('educaton'))
colnames(infert)
infert %>% select('educaton')
infert %>% select(-c('education'))
colnames(infert)
infert %>% select(-c('education', 'stratum'))
infert %>% select(-c('education', 'stratum')) %>% head
infert %>% select(-c('education', 'stratum')) %>% head -> infert_cont
ggplot(infert_cont) + geom_boxplot()
boxplot(infert_cont)
infert %>% select(-c('education', 'stratum'))-> infert_cont
boxplot(infert_cont)
infert %>% select(-c('education', 'stratum', 'pooled.stratum'))-> infert_cont
boxplot(infert_cont)
colnames(infert)
infert_cont$case
infert_cont$case
net.infert <- neuralnet(case ~ age + parity + induced + spontaneous, data=infert, hidden=2,
err.fct='ce', linear.output = F, likelihood = T)
net.infert
plot(net.infert)
names(net.infert)
net.infert$result.marix
net.infert$result.matrix
net.infert$covariate
net.infert$net.result[[1]]
out <- cbind(net.infert$covariate, net.infert$net.result[[1]])
out
dimnames(out) <- list(NULL, c('age', 'party', 'induced', 'spontaneous', 'nn-output'))
head(out)
head(net.infert$generalized.weights[[1]])
par(mfrow=c(2,2))
gwplot(net.infert, selected.covariate = 'age', min=-2.5, max=5)
gwplot(net.infert, selected.covariate = 'induced', min=-2.5, max=5)
gwplot(net.infert, selected.covariate = 'spontaneous', min=-2.5, max=5)
gwplot(net.infert, selected.covariate = 'spontaneous', min=-2.5, max=5)
compute(net.infert, covariate=matrix(c(22, 1, 0, 0,
22, 1, 1, 0,
22, 1, 0, 1,
22, 1, 1, 1),
byrow=TRUE, ncol=4))
compute(net.infert, covariate=matrix(c(22, 1, 0, 0,
22, 1, 1, 0,
22, 1, 0, 1,
22, 1, 1, 1),
byrow=TRUE, ncol=4))
covariate=matrix(c(22, 1, 0, 0,
22, 1, 1, 0,
22, 1, 0, 1,
22, 1, 1, 1),
byrow=TRUE, ncol=4)
covariate
covariate_mat = matrix(c(22, 1, 0, 0, 22, 1, 1, 0, 22, 1, 0, 1, 22, 1, 1, 1),
byrow=TRUE, ncol=4)
covariate_mat
compute(net.infert, covariate_mat)
net.infert <- neuralnet(case ~ age + parity + induced + spontaneous, data=infert, hidden=2,
err.fct='ce', linear.output = F, likelihood = T)
compute(net.infert, covariate_mat)
runif(50, min=0, max=100)
as.data.frame(runif(50, min=0, max=100))
train.input <- as.data.frame(runif(50, min=0, max=100))
train.output <- sqrt(train.input)
train.data <- cbind(train.input, train.output)
colnames(train.data)
colnames(train.data) <- c('input','output')
head(train.data)
net.sqrt <- neuralnet(output ~ input, train.data, hidden=10, threshold=.01)
print(net.sqrt)
plot(net.sqrt)
test.data <- as.data.frame((1:10)^2)
test.out <- compute(net.sqrt, test.data)
test.out <- neuralnet :: compute(net.sqrt, test.data)
new.output <- neuralnet :: compute(net.infert, covariate_mat) ## error
new.output$net.result
train.input <- as.data.frame(runif(50, min=0, max=100))
train.output <- sqrt(train.input)
train.data <- cbind(train.input, train.output)
colnames(train.data) <- c('input','output')
head(train.data)
net.sqrt <- neuralnet(output ~ input, train.data, hidden=10, threshold=.01)
print(net.sqrt)
plot(net.sqrt)
test.data <- as.data.frame((1:10)^2)
test.out <- neuralnet :: compute(net.sqrt, test.data)
ls(test.oiut)
ls(test.out)
print(test.out$net.result)
net2.sqrt <- neuralnet(output ~ input, train.data, hidden=c(10, 8), threshold = .01)
plot(net2.sqrt)
test2.out <- neuralnet :: compute(net2.sqrt, test.data)
print(test2.out$net.result)
# decison tree
library(rpart)
c <- rpart(Species ~, data=iris)
c
c <- rpart(Species ~, data=iris)
c <- rpart(Species ~ ., data=iris)
c
plot(c, compress=T, margin = .3)
text(c, cex=1.5)
plot(c, compress=T, margin = .3)
text(c, cex=1.5)
predict(c, newdata = iris, type='class')
prp(c, type=4, extra=2)
library(rpart.plot)
install.packages('rpart.plot')
library(rpart.plot)
prp(c, type=4, extra=2)
ls(c)
c$cptable
opt <- which.min(c$cptable[,'xerror'])
cp <- c$cptable[opt, 'CP']
prune.c <- prune(c, cp=cp)
plot(prune.c)
text(prune.c, use.n=T)
plotcp(c)
library(party)
install.packages('party')
library(party)
data("stagec")
str(stagec)
complete.cases(stagec)
stagec[complete.cases(stagec)]
stagec1 <- subset(stagec, !is.na(g2))
stagec2 <- subset(stagec, !is.na(gleason))
stagec3 <- subset(stagec, !is.na(eet))
str(stagec)
str(stagec3)
data("stagec")
str(stagec)
stagec1 <- subset(stagec, !is.na(g2))
stagec2 <- subset(stagec, !is.na(gleason))
stagec3 <- subset(stagec, !is.na(eet))
str(stagec3)
str(stagec3)
stagec1 <- subset(stagec, !is.na(g2))
data("stagec")
str(stagec)
stagec1 <- subset(stagec, !is.na(g2))
stagec2 <- subset(stagec1, !is.na(gleason))
stagec3 <- subset(stagec2, !is.na(eet))
str(stagec3)
set.seed(1234)
ind <- sample(2, nrow(stagec3), replace=T, prob=c(.7, .3))
ind
trainData <- stagec3[ind==1, ]
testData <- stagec3[ind==2, ]
tree <- ctree(ploidy ~., data=trainData)
tree
plot(tree)
testPred = predict(tree, newdata=testData)
table(testPred, testData$ploidy)
testData$ploidy
testData$ploidy %>% group_by(ploidy) %>% count()
testData$ploidy %>% count(N)
testData
testData %>% group_by(ploidy) %>% count(N)
testData %>% group_by(ploidy) %>% count()
subset(airquality, !is.na(Ozone))
data("airquality")
subset(airquality, !is.na(Ozone))
airq <- subset(airquality, !is.na(Ozone))
head(airq)
airct <- ctree(Ozone ~., data=airq)
airct
plot(airct)
# 예측값은 최종 마디에 대한 자료들의 평균값
head(predict(airct, data=airq))
# type='node'
predict(airct, data=airq, type='node')
mean((airq$Ozone - predict(airct^))^2)
mean((airq$Ozone - predict(airct^)^2)
mean((airq$Ozone - predict(airct)^2)
mean((airq$Ozone - predict(airct))^2)
mean((airq$Ozone - predict(airct))^2)
library(adabag)
install.packages('adabag')
library(adabag)
data(iris)
iris.bagging <- bagging(Species ~., data=iirs, mfinal=10)
iris.bagging <- bagging(Species ~., data=iris, mfinal=10)
iris.bagging$importance
plot(iris.bagging$trees[[10]])
text(iris.bagging$trees[[10]])
pred <- predict(iris.bagging, newdata = iris)
