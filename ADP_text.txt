1과목_3장_2절_1

1_3_2_1

 - 데이터 분석에서 데이터 사이언스로 가야 함. 전략적 통찰을 추구하고 비즈니스 핵심 이슈에 답을 하고, 사업의 성과를 견인
1_3_2_2

 - IT 영역, 분석영역, 비즈니스 컨설팅 영역
 - 데이터사이언티스트 : 데이터 홍수 속에서 헤엄, 데이터 소스 찾기, 데이터 구조화, 불완전한 데이터 연결, 문제이면 파악, 질문 찾기, 검증 가능한 가설 설정, 통계적 지식 활용 패턴이나 통찰력 도출, 결과정보의 시각적 도출 등 효과적인 커뮤니케이션
 - 하드스킬, 소프트스킬(사고방식, 비즈니스 이슈에 대한 감각, 고객들에 대한 공감능력 등) 

1_3_2_4 : 전략적 통찰력과 인문학의 부활
 - 단순 세계화에서 복잡한 세계화
 - 제품생산에서 서비스로 이동
 - 생산에서 시장창조로 변화

1_3_2_5 : 데이터 사이언티스트에 요구되는 인문학적 사고의 특성과 역할
 - 비판이란 다른 사람의 생각을 헐뜯는 것이 아닌 그런 생각을 할 수밖에 없도록 만들었던 것을 들춰내는 일
 - 왜 우리가 이런 식으로 생각했나, 왜 우리는 세상이 그런 것인 줄만 알았나? 물음을 던지는 것이 인문학

1_3_2_6 : 데이터 분석 모델링에서 인문학적 통찰력의 적용 사례
 - 인간을 바라보는 관점
 - 성향적 관점 / 행동적 관점 / 상황적 관점

1_3_2_1 : 빅데이터 시대

1_3_2_2 : 빅데이터 회의론을 넘어 : 가치 패러다임의 변화
 - 빅데이터를 한때의 유행으로 여겨 그 핵심에 놓인 데이터 사이언스의 가치를 제대로 보지 못한다면 정말 치명적인 결과를 초래할 것

1_3_2_3 : 데이터 사이언스의 한계와 인문학
 - 모든 분석은 가정에 근거
 - 훌륭한 데이터사이언티스트는 인문학자들처럼 모델의 능력에 대해 항상 의구심을 가지고 가정들과 현실의 불일치에 대해 끊임없이 고찰하고, 분석 모델이 예측할 수 없는 위험을 살피기 위해 현실 세계를 쳐다봐야 함.

Analytics / IT / 비즈니스 분석

빅데이터에 대한 이론적 지식
분석기술에 대한 숙련
통찰력 있는 분석 : 창의적 사고, 호기심, 논리적 비판
설득력 있는 전달 : 스토리텔링, 비주얼라이제이션
다분야간 협력 : 커뮤니케이션

2_1_1_1 : ETL 개요

2_1_1_2 : ODS 구성
 - 인터페이스 단계 : 데이터 원천들로부터 데이터를 획득하기 위한 프로토콜 : OLEDB, ODBC, FTP 등등 
 - 데이터 스테이징 단계
 - 데이터 프로파일링 단계 : 프로파일링, 결과 통계, 품질 보고서 생성 및 공유
 - 데이터 클렌징 단계 : 데이터 품질 보고서, 데이터 클렌징 요건, 클렌징 스토어드 프로시져 실행, 클렌징 ETL 도구 실행
 - 데이터 인테그레이션 : 데이터 클렌징 테이블, 데이터 충돌 판단 요건(통합 스토어드 프로시져 실행, 통합 ETL 도구 실행)
 - 익스포트 단계

2_1_1_3 : 데이터 웨어하우스
 - 주제중심 : 실 업무 상황의 특정 이벤크나 업무 항목을 기준으로 구조화
 - 영속성 
 - 통합성 
 - 시계열성 

 - 데이터 웨어하우스 테이블들은 스타스키마 또는 스노우 플레이크 스키마로 모델링 됨.
 - 스타스키마 : 이해 용이, 쿼리작성 용이,  테이블 적음 / 중복으로 인해 데이터 적재시 상대적으로 많은 시간 소요
 - 스노우 플레이크 스키마 : 조인 테이블 개수 증가 및 쿼리 작성 난이도 상승


2_1_2_1 : 데이터 웨어하우스 : CDC 개요
 - 실시간 또는 근접실시간 데이터 통합을 목적으로 함
 - Time Stamp on Rows
 - Version Numbers on Rows
 - Status on Rows
 - Time/Version/Status on Rows
 - Triggers on Tables
 - Event Programming
 - Log Scanner on Database

2_1_3_1 : EAI 개요
 - Hub and Spoke 방식의 EAI 기반 구조

2_1_3_2 : EAI 구현 유형
 - Mediation : Broker 
 - Federation : 외부 정보 시스템으로부터 데이터 요청들을 일괄적으로 수령해 필요한 데이터를 전달

2_1_3_3 : EAI 기대 효과


2_1_4_1 : 데이터 연계 및 통합 기법 요약
 - 일괄통합 
 - 비동기식 실시간 통합
 - 동기식 실시간 통합

 - 데이터 처리 기법 비교 : 전통적 데이터 저장 메커니즘 대비 매우 다수의 노드에 중복을 허용하는 방식으로 데이터를 저장하는 것은 빅데이터의 고유한 특성임.

2_1_5_1 : 대용량 비정형 데이터 처리
 - 초고속 수집 성능과 확장성
 - 데이터 전송 보장 메커니즘
 - 다양한 수집과 저장 플러그인

2_1_5_2 : 대규모 분산 병렬 처리
 - 선형적인 성능과 용량 확장
 - 고장 감내성
 - 핵심 비즈니스 로직에 집중
 - 풍부한 에코시스템 형성

2_1_5_3 : 데이터 연동
 - 스쿱

2_1_5_4 : 대용량 질의 기술
 - SQL on Hadoop
 - Drill, Stinger, Shark, Tajo, Impala, HAWQ, 프레스토


 - 임팔라 구성요소 : 클라이언트, 메타스토어, 임팔라 데몬, 스테이트스토어, 스토리지(HBase, HDFS)


2_2_1_1 : 분산 데이터 저장 기술, 분산파일시스템

 - 비대칭형 클러스터 파일 시스템(파일 메타데이터 관리 전용 서버...)
 - 구글 파일 시스템
   - 작업 부하는 연속적으로 많은 데이터를 읽는 연산이거나 임의의 영역에서 적은 데이터를 읽는 연산
   - 파일에 대한 쓰기 연산은 주로 순차적으로 데이터를 추가하며, 파일에 대한 갱신은 드물게 이루어짐
   - 여러 클라이언트에서 동시에 동일한 파일에 데이터를 추가하는 환경에서 동기화 오버헤드를 최소화할 수 있는 방법 요구
   - 낮은 응답 지연시간보다 높은 처리율이 중요
   - chunk, 마스터, 하트비트, chunk 재복제, 재분산


 - 하둡분산파일 시스템

 - 러스터
  - 객체기반클러스터 파일시스템
  - 클라이언트 파일시스템, 메타데이터서버, 객체저장서버
  - 객체는 객체 저장 서버들에 스트라이핑되어 분산 저장됨
  - UNIX 시맨틱, 메타데이터 Write Back Cache
  - 파일 메타데이터와 파일 데이터에 대한 동시성 제어를 위해 별도의 잠금 사용
  - 메타데이터에 접근 위해 메타데이터 서버 잠금 획득
  - 인텐트 기반 잠금 프로토콜 사용(네트워크간 트래픽 감소)
  - POSIX support, Supports file modification 지원

2_2_1_2 : 데이터 베이스 클러스터
  - 데이터베이스 파티션닝
   - 병렬처리 --> 빠른 검색 처리
   - 성능의 선형적 증가
   - 고가용성(서비스 지속)

  - 무공유

  - Oracle RAC 
    - 특정노드가 데이터를 소유하는 개념 없음
    - 성능향상을 위해 파티션닝 빈번
    - 가용성 : 장애시 나머지 노드에서 지속 실행
    - 확장성 : 최대 100개 노드 지원 
    - 비용절감 : 4개 노드 정도

  - 공유디스크
   - SAN
   - 높은 수준의 폴트톨러런스
   - 디스크 영역 내 병목현상

 - IBM DB2 ICE
   - 무공유 방식의 클러스터링
   - Single View Database
   - 각 노드로 분산되는 파티션닝을 어떻게 구성하느냐에 따라 성능 차이 다대
   - 노드 장애시 별도의 페일오버 메커니즘 필요
   - DB2를 이용하여 클러스터를 구성할 때에도 가용성을 보장하기 위해 공유 디스크 방식 이용

 - 마이크로소프트 SQL Server
   - 연합(Federated) 데이터베이스
   - 테이블을 논리적으로 분리해 물리적으로는 분산된 각 노드에 생성하고, 각 노드의 데이터베이스 인스턴스 사이에 
     링크를 구성한 후 모든 파이션에 대해 UNION ALL을 이용해 논리적인 View를 구성 --> 싱들 뷰 제공
   - 전역 스키마 정보가 없기 때문데 질의 수행을 위해 모든 노드 액세스 필요

 - MySQL 
   - 메모리기반 데이터베이스 클러스터링 지원
   - 병렬 서버구조 확장 용이
   - 관리노드 : 클러스터를 관리하는 노드로 클러스터 시작과 재구성 시에만 관여
   - 데이터노드 : 클러스터의 데이터를 저장하는 노드
   - MySQL 노드 : 클러스터 데이터 접근을 지원하는 노드
   - 장애 발생되어 복구시 데이터 동기화 작업 자동 실행
   - 버전 5.1.6 이상에서 디스크 기반 클러스터링 제공 / 디스크에 저장된 데이터는 모두 인덱스가 없는 데이터
   - linear key 파티셔닝
   - 노드수는 255개 제한, 데이터노드는 최대 48개까지
   - 전체 트랜젝션 이전으로 롤백
   - 컬럼명 31자, DB 및 테이블명 길이는 122자로 제한
   - 클러스터에서 생성할 수 있는 테이블 수는 최대 2만 320개, 한 로우의 최대크기는 8KB, 테이블키는 최대 32개

 - NoSQL
  - 구글 빅테이블 
    - AppEngine 에서 사용
    - multi-dimension sorted hash map을 파티션하여 분산 저장하는 저장소
    - table 내 모든 데이터는 row-key 사전적 순서로 정렬저장
    - 정렬순서 : rowkey + columnkey + timestamp
    - 분리된 파티션 Tablet
    - 공유 디스크 방식, 모든 노드가 데이터, 인덱스 파일 공유
    - SPOF : Single Point of Failure 마스터
    - Chubby 마스터 관찰

 - AppEngine
    - 내부적으로 빅테이블 이용
    - 빅테이블 : HBase, Neptune

 - 아마존 SimpleDB
    - 웹 애플리케이션에서 사용하는 데이터 실시간 처리 지원
    - Eventual Consistency 정책
    - 전용 쿼리(ANSI SQL 안 됨)
    - 도메인(테이블)
    - Items(레코드)
    - Attribute(columns)
    - 여러 도메인에 걸친 쿼리는 불가
    - 1+N(master-slave)의 두 개의 도메인으로부터 데이터를 조회할 경우 쿼리가 여러번 수행되야 하는 단점 존재
    - CreateDomain, DeleteDomain, ListDomain, PutAttributes, DeleteAttributes, GetAttributes, Query

 - 마이크로소프트 SSDS
    - 컨테이너는 테이블과 유사한 개념이지만 하나의 컨테이너에 여러 종류의 엔티티 저장 가능
    - CustomerId가 파티셔닝 키가 되고 파티셔닝 대상은 켄테이너가 됨


2_2_2_1 : MapReduce
 - Map Task 하나가 1개의 블록을 대상으로 연산 수행
 - Map -- (Key, Value 리스트) -- Reduce
 - 정렬 같은 양이 줄지 않는 작업에는 부적합
 - 폴트롤러런스
 - 하둡 MapReduce : 네임노드, 데이터노드, JobTracker, TaskTracker
 - sort, 플랫폼 자체 성능 및 확장성 측정에 대한 좋은 실험

2_2_2_2 : 병렬 쿼리 시스템
 - 구글 Sawwzall
 - Pig : Map의 Output이 또 다른 Map의 Input으로 들어가야하고 Reduce의 Output이 다른 Map의 Input으로 
   들어가야하는 Chaining
 - 아파치 하이브 : Facebook 데이터 웨어하우스 인프라
 - 하이브 아키텍쳐
   - MetaStore
   - Embedded Derby
   - Execution Engine : 하둡의 JobTracker와 네임노드와 통신을 담당하는 창구
   - SerDe : 하둡의 InputFormat과 OutputFormat에 해당
 - DDL : Create Table, Drop Table, Rename Table, Alter Table, Add Column, Show Table, Describe Table
 - DML : Load data, 쿼리결과를 테이블이나 로컬 파일시스템, DFS에 저장
 - Query : Select, Group by, Sort by, Joins, Union, Sub Queries, Sampliing, Transform

2_2_2_3 : SQL on Hadoop
 - 임팔라 : 하둡과 Hbase에 저장된 데이터를 대상으로 SQL 질의 가능
 - 임팔라 데몬, JDBC나 ODBC 또는 임팔라셸을 이용하여 질의 요청 가능
 - DDL : Create Table, Drop Table, Rename Table, Alter Table, Add Column, Show Table, Describe Table
 - DML : Select, Wherem Groupby, OrderBy / 데이터변경 구문은 지원 안함 / Delete 지원 안 함
 - 내장함수 : 수학함수, 타입변환, 조건문, 문자열함수 등
 - 로우단위로 저장시 테이블에서 하나의 컬럼을 읽든 전체 테이블을 읽든 동일한 디스크 입출력이 발생
 - 컬럼단위 : 처리 성능 개선 가능

2_2_3 : 클라우드 인프라 기술
 - 인텔, AMD 등과 같은 CPU 제공업체는 하드웨어 차원의 CPU 가상화를 주로 다루며, VMware나 MS 등에서는 
   소프트웨어 기반의 가상화 제품을 내놓음
 - 가상머신 사이의 데이터보호, 예측하지 못한 장애로부터 보호, 공유자원에 대한 강제 사용의 거부, 서버통합,
   자원할당에 대한 증가된 유연성, 테스팅, 정확하고 안전한 서버 사이징, 시스템 관리

 - CPU 가상화
   - 하이퍼바이저 : 가상머신
   - 하드웨어 환경 에물레이션, 실행환경 격리, 시스템 자원 할당, 소프트웨어 스택 보존
   - 물리적인 하드웨어와 호스트 운영체제와의 관계 : 베어메탈, 호스트기반
   - 베어메탈 : 하드웨어와 호스트 운영체제 사이 --> 반가상화 및 완전가상화로 나뉨
   - 호스트 기반 하이퍼바이저 : 호스트 운영체제와 게스트 운영체제 사이
   - x86 아키텍펴의 가상화 기술의 핵심은 가상머신이 요청하는 previleged 명령어를 어떻게, 어떤 계층에서 처리하는가 임. 
   - 완전가상화, 반가상화라는 용어도 previleged 명령어를 어떻게 처리하느냐를 기준으로 분류
   - 완전가상화는 하이퍼바이저보다 우선순위가 낮은 가상머신에서는 실행되지 않는 previleged 명령어에 대해서 trap을 발생시켜
     하이퍼바이저에서 실행하는 방식으로 MS 윈도우와 같은 Guest OS가 하이퍼바이저 상에서 변경되지 않은 상태로 실행될 수
     있는 장점이 있으나 Para Virtualization에 비해 속도가 느림
   - 하드웨어 지원 완전가상화 : 하이퍼바이저는 Ring -1에서 수행, 가상머신의 운영체는 Ring 0에서 수행, previleged 명령어에
     대해 추가 변환 과정 필요 없음
   - 윈도우 2008 서버의 Hyper-V는 반드시 가상화 지원 CPU만 사용
   - 하드웨어 지원 가상화를 사용하는 경우 CPU 사용률이 높아진다. 특히 I/O나 메모리를 많이 사용하는 경우 CPU 사용률이 높아짐
   - 서버 통합을 목적으로 하는 경우 비효율적일 수 있음
   - 반가상화는 previleged 명령어를 게스트 운영체제에서 hypercall로 하이퍼바이저에 전달하고 하이퍼바이저는 hypercall에 대해
     previleged 레벨에 상관없이 하드웨어 명령을 실행하는 call을 말함
   - 반가상화 기반에서는 CPU와 메모리 자원의 동적 변경이 서비스의 중단 없이 이루어질 수 있으며 완전가상화에 비해 성능이 뛰어남
   - 반가상화는 커널을 변경해야 하고 완전가상화는 속도는 느리나 커널 변경이 없음.


































































































































































