---
title: "Confusion Matrix in R"
author: "Daniel_Kim"
date: '2019 11 30 '
output: rmarkdown::github_document
---

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(neuralnet)
library(rpart)
```

혼돈행렬에 대해 알아본다. 신경망모형과 의사결정나무 모형 두 모형을 만들고 각각의 
모형의 `accuracy`, `precision`, `recall`, `f1` 값들을 어떻게 구할 수 있는지를 알아보자.

먼저 신경망 모형을 R `neuralnet` 패키지를 활용하자.

학습을 위해 사용할 데이터는 `setosa` 종을 제외한 `iris_1` 데이터이다.

```{r}
iris %>%
  filter(Species %in% c('versicolor', 'virginica')) -> iris_1

iris_1$Species <- factor(iris_1$Species, levels = c('versicolor', 'virginica'))
table(iris_1$Species)

```

데이터를 훈련용과 테스트용 데이터로 분리한다.

```{r}
library(caret)

train_idx <- createDataPartition(iris_1$Species, p = .8, list = F)[, 1]
test_idx <- setdiff(1:nrow(iris_1), train_idx)

train_set <- iris_1[train_idx, ]
test_set <- iris_1[test_idx, ]
```

```{r}
train_set$Species %>% table()
```

```{r}
test_set$Species %>% table()
```



훈련용 데이터를 이용하여 신경망 모형을 생성한다.

```{r}
m_nnet <- neuralnet(Species ~ ., data = train_set, hidden = 2, err.fct = 'ce', linear.output = F,
                    likelihood = T)

m_nnet %>% summary()
```


신경망모형의 예측값을 확인한다.

```{r}
compute(m_nnet, test_set)$net.result[, 2] %>%
  enframe() %>%
  mutate(y_pred_class = ifelse(value >= .5, 1, 0)) %>%
  select(y_pred_class) %>%
  pull() -> vec.yhat_nnet_class; vec.yhat_nnet_class
```

다음으로는 동일한 훈련용 데이터를 이용하여 의사결정나무 모델을 훈련시킨다.

```{r}
m_rpart <- rpart(Species ~ ., data = train_set)

m_rpart
```

```{r, message=FALSE, warning=FALSE}
library("rattle")
fancyRpartPlot(m_rpart)
```

의사결정나무의 예측값을 구한다

```{r}
predict(m_rpart, test_set, type = 'prob')[, 2] %>%
  enframe() %>%
  mutate(y_pred_class = ifelse(value >= .5, 1, 0)) %>%
  select(y_pred_class) %>%
  pull() -> vec.yhat_rpart_class; vec.yhat_rpart_class
```


이제부터 각 모델에 대한 혼돈행렬을 만들고 각 혼돈행렬을 이용, 각 모델의 `accuarcy`, 
`precision`, `recall`, `f1` 값들을 구한다.


```{r}
actual <- test_set$Species %>% 
  as.numeric(.) - 1

actual <- actual %>% as.factor()

yhat_nn <- vec.yhat_nnet_class %>% as.factor()

yhat_rpart <- vec.yhat_rpart_class %>% as.factor()

result <- data.frame(actual = actual, 
                     yhat_nn = yhat_nn, 
                     yhat_rpart = yhat_rpart)

result
```

`caret` 패키지의 `confusionMatrix()` 함수를 이용하려면 비교하는 원소들이 `factor`형으로 저장되어 있어야 한다.

```{r}
library(caret)
nn_con <- confusionMatrix(result$actual, result$yhat_nn)
dt_con <- confusionMatrix(result$actual, result$yhat_rpart)
```



```{r}
nn_con$table
```

```{r}
dt_con$table
```

Metrics 패키지를 이용하려면 원소들이 숫자형으로 채워져 있어야 한다. `factor`형으로 되어 있는
result를 `numeric` 형으로 바꾸어준다.


```{r}
library(Metrics)

result %>%
  mutate(actual = as.numeric(actual) - 1) %>%
  mutate(yhat_nn = as.numeric(yhat_nn) - 1) %>%
  mutate(yhat_rpart = as.numeric(yhat_rpart) - 1) -> result_1

result_1 %>% str()
```

각각의 지표값들을 구한다. 

```{r}
accuracy <- c(accuracy(result_1$actual, result_1$yhat_nn),
              accuracy(result_1$actual, result_1$yhat_rpart))
# accuracy

precision <- c(Metrics::precision(result_1$actual, result_1$yhat_nn), 
               Metrics::precision(result_1$actual, result_1$yhat_rpart))

# precision

recall <- c(recall(result_1$actual, result_1$yhat_nn),
            recall(result_1$actual, result_1$yhat_rpart))

# recall

f1_score <- c(f1(result_1$actual, result_1$yhat_nn), 
              f1(result_1$actual, result_1$yhat_rpart))

# f1_score

data.frame(
  model  = c('neuralnet', 'rpart'),
  accuracy = accuracy,
  precision = precision,
  recall = recall,
  f1_score = f1_score
) %>%
  gather(variable, value, -model) %>%
  spread(model, value) -> df_scores

df_scores
```

### ROC 그래프

```{r}
data('infert')
infert %>% head()
```

```{r}
summary(infert)
```

```{r}
str(infert)
```

```{r}
infert %>%
  dplyr::select(case, age, parity, induced, spontaneous) -> infert_1

infert_1 %>% head()
```

데이터를 훈련용과 테스트용으로 분리한다.

```{r}
library(caret)

set.seed(2019)
train_idx <- createDataPartition(infert_1$case, p = .7, list  = F)[, 1]
test_idx <- setdiff(1:nrow(infert_1), train_idx)
```

```{r}
train_set <- infert_1[train_idx, ]
test_set <- infert_1[test_idx, ]
```

```{r}
train_set$case %>% table()
```

```{r}
test_set$case %>% table()
```

`neuralnet`, `C5.0` 을 이용하여 모델을 생성한다.

neuralnet 모델 생성은 다음과 같이 한다.

```{r}
m_nnnet <- neuralnet(case ~ ., data = train_set, hidden = 3, err.fct = 'ce', linear.output = F, 
          likelihood = T)

m_nnet %>% summary()
```

C5.0 모델 생성은 다음과 같이 한다

```{r}
library(C50)
train_set$case <- as.factor(train_set$case)
m_dt <- C5.0(case ~ ., data = train_set)
```

테스트 데이터에 대한 각 모델의 예측값들을 구한다. 먼저 다음과 같이 `m_nnnet` 모델에 대한 예측값을 구한다.

```{r}
predict(m_nnnet, newdata = test_set, type = 'prob') %>%
  as_tibble() %>%
  # mutate(V1 = ifelse(V1 >= .5, 1, 0)) %>%
  rename(yhat_nn = V1) -> df_yhat_nn

df_yhat_nn
```

그리고 `m_dt` 모델에 대한 예측값을 다음과 같이 구한다.

```{r}
predict(m_dt, newdata = test_set, type ='prob') %>%
  as_tibble() %>%
  dplyr::select('1') %>%
  # mutate(value = as.numeric(value) - 1) %>%
  rename(yhat_dt = '1') -> df_yhat_dt


df_yhat_dt
```

결과값들을 하나의 데이터 프레임에 담아보자..

```{r}
test_set$case %>%
  as_tibble() %>%
  rename(actual = value) %>%
  bind_cols(df_yhat_nn) %>%
  bind_cols(df_yhat_dt) -> df_result

df_result
```

이제 위의 결과값을 이용하여 ROC 그래프를 그려보자.

```{r}
library(ROCR)
y_obs <- df_result$actual %>% as.factor()
y_pred_nn <- prediction(df_result$yhat_nn, y_obs)
y_perf_nn <- performance(y_pred_nn, measure = 'tpr', x.measure = 'fpr')

y_pred_dt <- prediction(df_result$yhat_dt, y_obs)
y_perf_dt <- performance(y_pred_dt, measure = 'tpr', x.measure = 'fpr')
```

```{r}
plot(y_perf_nn, col = 'red')
plot(y_perf_dt, add = T, col ='blue')
abline(0, 1)
```

```{r}
performance(y_pred_nn, 'auc')@y.values[[1]]
```

```{r}
performance(y_pred_dt, 'auc')@y.values[[1]]
```

여기서 신경망 모형의 향상도 곡선을 그려보자.

```{r}
nn_lift <- performance(y_pred_nn, 'lift', 'rpp')
plot(nn_lift)
abline(v = .2, col = 'red')
abline(h = 2, col ='blue')
```

결과적으로 신경망 모형의 경우 상위 20%  집단에 대해 랜덤 모델과 비교시 약 2배의 성과향상을 보인다.